{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d14d236-e8ca-4718-9c96-4527be31f2a9",
   "metadata": {},
   "source": [
    "# Analysis for Zero Shot FlowJudge and GLIDER\n",
    "\n",
    "Here, we look at the initial results obtained when running FlowJudge and GLIDER with zero shot prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2ae4a3-d738-48e2-934d-d2bed2440d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0cb8b9-e171-4fbe-9eec-fc281fe5952d",
   "metadata": {},
   "outputs": [],
   "source": [
    "flowjudge_data = pd.read_csv(\"data/flowjudge_fc_results.csv\")\n",
    "glider_data = pd.read_csv(\"data/glider_fc_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3be12e-c0cd-4117-a6b9-f58bb9af5132",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    \"ST-Perfect\": True,\n",
    "    \"ir-ST-Perfect\": False,\n",
    "    \"ST-Imperfect\": False,\n",
    "    \"ir-ST-Imperfect\": False,\n",
    "    \"ST-External\": False,\n",
    "    \"ir-ST-External\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cabba2c-f77c-40d3-a933-e8d7dfc5bee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"FlowJudge\")\n",
    "print(f1_score(flowjudge_data.score.map(lambda x : x>2), flowjudge_data.b_id.map(mapping)))\n",
    "print(precision_score(flowjudge_data.score.map(lambda x : x>2), flowjudge_data.b_id.map(mapping)))\n",
    "print(recall_score(flowjudge_data.score.map(lambda x : x>2), flowjudge_data.b_id.map(mapping)))\n",
    "print(confusion_matrix(flowjudge_data.score.map(lambda x : x>2), flowjudge_data.b_id.map(mapping)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab39cd6-b2aa-4bcc-ba71-a7ac34929419",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GLIDER\")\n",
    "print(f1_score(glider_data.score.map(lambda x : x>2), glider_data.b_id.map(mapping)))\n",
    "print(precision_score(glider_data.score.map(lambda x : x>2), glider_data.b_id.map(mapping)))\n",
    "print(recall_score(glider_data.score.map(lambda x : x>2), glider_data.b_id.map(mapping)))\n",
    "print(confusion_matrix(glider_data.score.map(lambda x : x>2), glider_data.b_id.map(mapping)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2889fe-543a-4885-86be-80a2106d56cf",
   "metadata": {},
   "source": [
    "# Analysis for few shot FlowJudge\n",
    "\n",
    "Here, we look at two different metrics to evaluat how FlowJudge did as a function calling judge. First, we assess how stable FlowJudge during experimentation. We do this by passing the same data points three different times to FlowJudge (i.e. running the experiment three times), and then finding the `cohen_kappa_score` between the three runs pairwise. Second, for each experiment, we check the f1-score, precision, recall, and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a24a74aa-7032-4b4d-ae31-f0c2f41d20c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, cohen_kappa_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6393367-1b93-4d7d-b58b-0f50c817749e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hammerbench = pd.read_csv(\"/home/dni138/mozilla_ai/data/function_call_experiment.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d879f9d-a090-4038-b681-e7ac229d58a4",
   "metadata": {},
   "source": [
    "## Cohen Kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82ca4f9d-96b5-45ad-a1f9-fa9b9e9dd87e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26344492678403253"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohen_kappa_score(hammerbench.score_run_0, hammerbench.score_run_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9ffa005-28c1-404c-bf6d-5daba5e7a838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27004185295065264"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohen_kappa_score(hammerbench.score_run_1, hammerbench.score_run_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c34e5abc-c977-4e6d-a96e-ec25679e69e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27486275759596934"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohen_kappa_score(hammerbench.score_run_0, hammerbench.score_run_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd058e3e-acb1-4eb9-80a6-88e73f4c3a3c",
   "metadata": {},
   "source": [
    "## Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7437008a-2a47-4df0-9f7b-417b66c46325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['label', 'messages', 'tools', 'explanation_run_0', 'score_run_0',\n",
       "       'explanation_run_1', 'score_run_1', 'explanation_run_2', 'score_run_2',\n",
       "       'gt_label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hammerbench.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "70fcc7fe-8738-4089-a3d4-621a9abbc145",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_to_bool = {\n",
    "    0: False,\n",
    "    1: False,\n",
    "    2: True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2771f038-429e-438a-900e-70982f3521e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25142/2427440671.py:1: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  hammerbench[\"score_run_0\"].map(score_to_bool).fillna(False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        False\n",
       "1        False\n",
       "2        False\n",
       "3        False\n",
       "4        False\n",
       "         ...  \n",
       "13049    False\n",
       "13050    False\n",
       "13051    False\n",
       "13052    False\n",
       "13053    False\n",
       "Name: score_run_0, Length: 13054, dtype: bool"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hammerbench[\"score_run_0\"].map(score_to_bool).fillna(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8730b022-2026-4d9f-a3b1-d77d1439d875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------RUN_0-----------\n",
      "F1 Score: 0.5035039230266493\n",
      "Precision: 0.6131466994997525\n",
      "Recall: 0.5196778041969499\n",
      "Confusion Matrix: \n",
      "\n",
      " [[10743   195]\n",
      " [ 1995   121]] \n",
      "\n",
      "----------RUN_1-----------\n",
      "F1 Score: 0.5046584311020123\n",
      "Precision: 0.6251617793110659\n",
      "Recall: 0.5206912064252164\n",
      "Confusion Matrix: \n",
      "\n",
      " [[10760   178]\n",
      " [ 1994   122]] \n",
      "\n",
      "----------RUN_2-----------\n",
      "F1 Score: 0.49889597981284217\n",
      "Precision: 0.6054650923850642\n",
      "Recall: 0.5172079630126981\n",
      "Confusion Matrix: \n",
      "\n",
      " [[10751   187]\n",
      " [ 2007   109]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25142/741388246.py:3: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  print(\"F1 Score: {}\".format(f1_score(hammerbench.gt_label, hammerbench[\"score_run_{}\".format(i)].map(score_to_bool).fillna(False), average=\"macro\", labels=[False, True])))\n",
      "/tmp/ipykernel_25142/741388246.py:4: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  print(\"Precision: {}\".format(precision_score(hammerbench.gt_label, hammerbench[\"score_run_{}\".format(i)].map(score_to_bool).fillna(False), average=\"macro\", labels=[False, True])))\n",
      "/tmp/ipykernel_25142/741388246.py:5: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  print(\"Recall: {}\".format(recall_score(hammerbench.gt_label, hammerbench[\"score_run_{}\".format(i)].map(score_to_bool).fillna(False), average=\"macro\", labels=[False, True])))\n",
      "/tmp/ipykernel_25142/741388246.py:6: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  print(\"Confusion Matrix: \\n\\n {} \\n\".format(confusion_matrix(hammerbench.gt_label, hammerbench[\"score_run_{}\".format(i)].map(score_to_bool).fillna(False), labels=[False, True])))\n",
      "/tmp/ipykernel_25142/741388246.py:3: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  print(\"F1 Score: {}\".format(f1_score(hammerbench.gt_label, hammerbench[\"score_run_{}\".format(i)].map(score_to_bool).fillna(False), average=\"macro\", labels=[False, True])))\n",
      "/tmp/ipykernel_25142/741388246.py:4: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  print(\"Precision: {}\".format(precision_score(hammerbench.gt_label, hammerbench[\"score_run_{}\".format(i)].map(score_to_bool).fillna(False), average=\"macro\", labels=[False, True])))\n",
      "/tmp/ipykernel_25142/741388246.py:5: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  print(\"Recall: {}\".format(recall_score(hammerbench.gt_label, hammerbench[\"score_run_{}\".format(i)].map(score_to_bool).fillna(False), average=\"macro\", labels=[False, True])))\n",
      "/tmp/ipykernel_25142/741388246.py:6: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  print(\"Confusion Matrix: \\n\\n {} \\n\".format(confusion_matrix(hammerbench.gt_label, hammerbench[\"score_run_{}\".format(i)].map(score_to_bool).fillna(False), labels=[False, True])))\n",
      "/tmp/ipykernel_25142/741388246.py:3: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  print(\"F1 Score: {}\".format(f1_score(hammerbench.gt_label, hammerbench[\"score_run_{}\".format(i)].map(score_to_bool).fillna(False), average=\"macro\", labels=[False, True])))\n",
      "/tmp/ipykernel_25142/741388246.py:4: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  print(\"Precision: {}\".format(precision_score(hammerbench.gt_label, hammerbench[\"score_run_{}\".format(i)].map(score_to_bool).fillna(False), average=\"macro\", labels=[False, True])))\n",
      "/tmp/ipykernel_25142/741388246.py:5: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  print(\"Recall: {}\".format(recall_score(hammerbench.gt_label, hammerbench[\"score_run_{}\".format(i)].map(score_to_bool).fillna(False), average=\"macro\", labels=[False, True])))\n",
      "/tmp/ipykernel_25142/741388246.py:6: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  print(\"Confusion Matrix: \\n\\n {} \\n\".format(confusion_matrix(hammerbench.gt_label, hammerbench[\"score_run_{}\".format(i)].map(score_to_bool).fillna(False), labels=[False, True])))\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(\"----------RUN_{}-----------\".format(i))\n",
    "    print(\"F1 Score: {}\".format(f1_score(hammerbench.gt_label, hammerbench[\"score_run_{}\".format(i)].map(score_to_bool).fillna(False), average=\"macro\", labels=[False, True])))\n",
    "    print(\"Precision: {}\".format(precision_score(hammerbench.gt_label, hammerbench[\"score_run_{}\".format(i)].map(score_to_bool).fillna(False), average=\"macro\", labels=[False, True])))\n",
    "    print(\"Recall: {}\".format(recall_score(hammerbench.gt_label, hammerbench[\"score_run_{}\".format(i)].map(score_to_bool).fillna(False), average=\"macro\", labels=[False, True])))\n",
    "    print(\"Confusion Matrix: \\n\\n {} \\n\".format(confusion_matrix(hammerbench.gt_label, hammerbench[\"score_run_{}\".format(i)].map(score_to_bool).fillna(False), labels=[False, True])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28415449-9b21-4c7d-a5fc-39296b14be31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
